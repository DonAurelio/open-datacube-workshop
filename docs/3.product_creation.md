# Product Creation

The datacube needs to know about the properies of the scenes produced for every satellite we are interested in. As every satellite takes different **measurements**, then every image will have different data. The datacube needs to care about organizing data of images from the same satellite together. For each satellite a **Product** must be created in the datacube. Then scenes from the same satellite corresponds with the same datacube Product. 

Start the container configured on the first section and copy the scene downloaded into the *data* directory. Then check that the scene is in the container */data* directory.

```sh
(base) cube@7f5f41421fc7:~$ ls data/
LC080050572018120901T1-SC20190909195342.tar.gz  README.md
```

## Create the product LS8_OLI_LASRC to store Landsat 8 Scenes

The datacube require a folder on which it will place the Scenes that it has indexed/ingested for each Satellite (Product). For LS8_OLI_LASRC we will create that forlder into the **/dc_storage** as follows. 

```sh 
cp -r products/LS8_OLI_LASRC /dc_storage/
```

If you check the content of the **/dc_storage/LS8_OLI_LASRC** directory using the command below, you will get 3 files. But we only care about two of them, the **description_file.yml** will be used to tell the datacube which information a LS8_OLI_LASRC Scene contains. Then, the datacube will create a bunch of database tables to hold those data; The **ingest_file.yml** is the ingestion config file. "An ingestion config is a document which defines the way data should be prepared for high performance access. This can include slicing the data into regular chunks, reprojecting into to the desired projection and compressing the data."

```sh 
ls /dc_storage/LS8_OLI_LASRC

description_file.yml  ingest_file.yml  mgen_script.py
```

Check the products created in the datacube, if you don't have created one before this command will not display information

```sh
datacube product list
```

Use the product definition file to create a LS8_OLI_LASRC Product 

```sh 
datacube product add /dc_storage/LS8_OLI_LASRC/description_file.yml

Added "ls8_collections_sr_scene"
```

List the Products created on the datacube

```sh 
datacube product list

creation_time: null
description: Landsat 8 USGS Collection 1 Higher Level SR scene proessed using LaSRC.
    30m UTM based projection.
format: GeoTiff
id: 1
instrument: OLI_TIRS
label: null
lat: null
lon: null
name: ls8_collections_sr_scene
platform: LANDSAT_8
product_type: LaSRC
time: null
```

## Data Indexing and Ingestion

Scenes are indexed on the datacube database for ease acces such data through the datacube Python API. An optional step performed by the datacube is the ingestion. This step divide the scene in pieces called tiles. This pieces are stored in dc_stoarge and improve the performance on queries made to the datacube, more details in [2]. 

Create a folder for the landsat 8 scenes we are intended to index (and ingest) in */source_storage*

```sh 
mkdir /source_storage/LS8_OLI_LASRC
```

Copy the .tar.gz file you copied in /datacube_shared in /source_storage

```sh 
cp ~/data/LC080050572018122501T1-SC20190910190636.tar.gz /source_storage/LS8_OLI_LASRC
```

Use the ingestion script to load the Landsat 8 Scene into the datacube. If the password of the **cube** user is requested use **cube**. 

```sh 
./scripts/IngestBatch.sh /source_storage/LS8_OLI_LASRC/ /dc_storage/LS8_OLI_LASRC/ingest_file.yml /dc_storage/LS8_OLI_LASRC/mgen_script.py
```

Check all tasks run successfully

```sh 
8 successful, 0 failed
```

# Todo 

```sh 
sudo apt install libgdal-dev
```

# References

1. [Product](https://datacube-core.readthedocs.io/en/latest/architecture/data_model.html#product)
2. [Indexing Data](https://datacube-core.readthedocs.io/en/latest/ops/indexing.html#indexing-data)

